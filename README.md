# Recurrent-Neural-Network
Implementations of a general Recurrent Neural Network classes that is trained with FORCE learning or Gradient Descent. We will use Dynamics Components Analysis and other statistical analysis techniques to map its activity onto low-dimensional subspaces and understand how network dynamics change during and after the training period.

Based on the paper, "Generating Coherent Patterns of Activity from Chaotic Neural Networks" by Sussillo and Abbott, 2009

See the initial results at initial_results.pdf for more information. Also, look in the Test folder for implementation examples.

We are planning on training the network on tasks similar to those used in the paper, "Task representations in neural networks trained to
perform many cognitive tasks" by Yang et. al. (2019). 

